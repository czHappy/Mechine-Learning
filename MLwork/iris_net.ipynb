{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from  sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata():\n",
    "    train_data=load_iris()\n",
    "    data=train_data['data']\n",
    "    labels=train_data['target'].reshape(-1,1)\n",
    "    total_data=np.hstack((data,labels))\n",
    "    np.random.shuffle(total_data)\n",
    "    train=total_data[0:120,:-1]\n",
    "    test=total_data[120:,:-1]\n",
    "    train_label=total_data[0:120,-1].reshape(-1,1)\n",
    "    test_label=total_data[120:,-1].reshape(-1,1)\n",
    "    return data,labels,train,test,train_label,test_label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "******************************************************************************************\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "******************************************************************************************\n",
      "[[4.9 3.1 1.5 0.2]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [5.  2.  3.5 1. ]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [7.7 2.6 6.9 2.3]]\n",
      "******************************************************************************************\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "data,labels,train,test,train_label,test_label = getdata()\n",
    "print(data)\n",
    "print('*'*90)\n",
    "print(labels)\n",
    "print('*'*90)\n",
    "print(train)\n",
    "print('*'*90)\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.14213389  0.03780185 -1.26585576 -1.27478726]\n",
      " [-1.14213389 -1.54987577 -0.22423731 -0.23591139]\n",
      " [ 0.35030967 -0.64263142  0.18083654  0.15366706]\n",
      " [-0.27154181 -0.18900924  0.470175    0.41338602]\n",
      " [-0.39591211 -1.09625359  0.41230731  0.02380757]\n",
      " [-0.27154181 -0.18900924  0.23870423  0.15366706]\n",
      " [ 1.09653144  0.03780185  0.58591038  0.41338602]\n",
      " [ 1.71838292  1.17185729  1.39605807  1.71198085]\n",
      " [-0.02280122 -0.64263142  0.81738115  1.58212137]\n",
      " [-0.39591211  0.9450462  -1.38159115 -1.27478726]\n",
      " [ 1.22090174 -0.64263142  0.64377807  0.28352654]\n",
      " [-1.51524477  0.71823511 -1.32372345 -1.14492778]\n",
      " [-1.76398537 -0.18900924 -1.38159115 -1.27478726]\n",
      " [ 0.84779085 -0.64263142  0.52804269  0.41338602]\n",
      " [ 0.84779085 -0.18900924  1.04885192  0.80296447]\n",
      " [-0.39591211  2.53272381 -1.32372345 -1.27478726]\n",
      " [ 1.09653144  0.03780185  1.10671961  1.58212137]\n",
      " [-1.01776359  0.71823511 -1.20798807 -1.01506829]\n",
      " [-0.39591211 -1.54987577  0.00723346 -0.23591139]\n",
      " [ 0.35030967 -0.41582033  0.58591038  0.28352654]\n",
      " [ 0.22593937 -2.00349794  0.75951346  0.41338602]\n",
      " [ 0.72342056  0.26461294  0.93311653  1.45226189]\n",
      " [-0.39591211 -1.77668685  0.18083654  0.15366706]\n",
      " [ 1.22090174  0.26461294  1.28032269  1.45226189]\n",
      " [-1.26650418  0.71823511 -1.20798807 -1.27478726]\n",
      " [ 0.35030967 -0.64263142  0.58591038  0.02380757]\n",
      " [-0.02280122 -0.8694425   0.23870423 -0.23591139]\n",
      " [ 0.10156908 -0.18900924  0.29657192  0.41338602]\n",
      " [ 1.09653144  0.49142402  1.1645873   1.19254292]\n",
      " [-1.01776359  1.17185729 -1.32372345 -1.27478726]\n",
      " [-1.26650418 -0.18900924 -1.32372345 -1.14492778]\n",
      " [-0.14717152  2.98634599 -1.26585576 -1.01506829]\n",
      " [-0.89339329  1.62547946 -1.03438499 -1.01506829]\n",
      " [ 1.09653144  0.49142402  1.1645873   1.71198085]\n",
      " [-0.14717152  1.62547946 -1.15012038 -1.14492778]\n",
      " [ 2.588975    1.62547946  1.56966115  1.06268344]\n",
      " [-0.52028241  1.85229055 -1.38159115 -1.01506829]\n",
      " [-0.769023    2.30591272 -1.26585576 -1.40464674]\n",
      " [-0.27154181 -0.64263142  0.70164577  1.06268344]\n",
      " [ 0.59905026 -1.77668685  0.41230731  0.15366706]\n",
      " [-0.52028241  0.71823511 -1.26585576 -1.01506829]\n",
      " [ 0.84779085  0.26461294  0.81738115  1.06268344]\n",
      " [ 0.35030967 -0.18900924  0.52804269  0.28352654]\n",
      " [-0.14717152 -0.41582033  0.29657192  0.15366706]\n",
      " [ 0.22593937 -0.41582033  0.470175    0.41338602]\n",
      " [-0.02280122 -1.09625359  0.18083654  0.02380757]\n",
      " [-0.14717152 -1.32306468  0.75951346  1.06268344]\n",
      " [ 0.59905026 -0.64263142  0.81738115  0.41338602]\n",
      " [-1.51524477  0.03780185 -1.26585576 -1.27478726]\n",
      " [ 0.97216115 -0.18900924  0.41230731  0.28352654]\n",
      " [ 2.34023441 -0.18900924  1.39605807  1.45226189]\n",
      " [ 0.47467996 -2.00349794  0.470175    0.41338602]\n",
      " [ 1.22090174 -0.18900924  1.04885192  1.19254292]\n",
      " [-1.39087448  0.26461294 -1.38159115 -1.27478726]\n",
      " [ 1.09653144  0.03780185  0.41230731  0.28352654]\n",
      " [ 1.09653144 -0.18900924  0.87524884  1.45226189]\n",
      " [ 1.34527204  0.26461294  1.1645873   1.45226189]\n",
      " [-1.51524477  0.26461294 -1.32372345 -1.27478726]\n",
      " [ 1.84275322 -0.41582033  1.51179345  0.80296447]\n",
      " [-0.6446527   1.39866837 -1.26585576 -1.27478726]\n",
      " [ 0.59905026  0.71823511  1.10671961  1.58212137]\n",
      " [-0.14717152 -1.09625359 -0.10850192 -0.23591139]\n",
      " [ 0.47467996 -0.41582033  0.35443961  0.15366706]\n",
      " [-1.88835566 -0.18900924 -1.49732653 -1.40464674]\n",
      " [ 0.22593937 -0.8694425   0.81738115  0.54324551]\n",
      " [ 0.22593937 -2.00349794  0.18083654 -0.23591139]\n",
      " [ 0.59905026  0.49142402  1.33819038  1.71198085]\n",
      " [-1.76398537  0.26461294 -1.38159115 -1.27478726]\n",
      " [-0.89339329  0.71823511 -1.26585576 -1.27478726]\n",
      " [ 1.34527204  0.03780185  0.99098423  1.19254292]\n",
      " [-0.39591211 -1.54987577  0.06510115 -0.10605191]\n",
      " [ 0.35030967 -0.18900924  0.70164577  0.80296447]\n",
      " [-1.01776359 -1.77668685 -0.22423731 -0.23591139]\n",
      " [ 0.59905026 -1.32306468  0.75951346  0.93282395]\n",
      " [ 1.59401263 -0.18900924  1.28032269  1.19254292]\n",
      " [-0.02280122 -0.8694425   0.81738115  0.93282395]\n",
      " [ 0.59905026 -0.8694425   0.70164577  0.80296447]\n",
      " [ 1.71838292  0.26461294  1.33819038  0.80296447]\n",
      " [ 0.47467996  0.71823511  0.99098423  1.45226189]\n",
      " [-1.14213389  1.17185729 -1.32372345 -1.40464674]\n",
      " [-1.01776359 -2.45712012 -0.10850192 -0.23591139]\n",
      " [-1.39087448  0.26461294 -1.20798807 -1.27478726]\n",
      " [ 0.72342056 -0.41582033  0.35443961  0.15366706]\n",
      " [ 1.34527204  0.03780185  0.81738115  1.45226189]\n",
      " [ 1.96712352 -0.64263142  1.39605807  0.93282395]\n",
      " [ 0.84779085 -0.18900924  0.87524884  1.06268344]\n",
      " [-1.01776359  0.71823511 -1.26585576 -1.27478726]\n",
      " [ 1.46964233  0.26461294  0.58591038  0.28352654]\n",
      " [ 0.84779085 -0.18900924  1.22245499  1.3224024 ]\n",
      " [ 0.59905026 -0.41582033  1.10671961  0.80296447]\n",
      " [-0.89339329 -1.32306468 -0.39784038 -0.10605191]\n",
      " [-0.27154181 -0.41582033 -0.05063423  0.15366706]\n",
      " [-1.76398537 -0.41582033 -1.32372345 -1.27478726]\n",
      " [ 0.97216115 -0.41582033  0.52804269  0.15366706]\n",
      " [-0.02280122  2.07910164 -1.43945884 -1.27478726]\n",
      " [-0.52028241 -0.18900924  0.470175    0.41338602]\n",
      " [-0.89339329  0.9450462  -1.32372345 -1.14492778]\n",
      " [-0.14717152 -0.64263142  0.470175    0.15366706]\n",
      " [-0.89339329  0.49142402 -1.15012038 -0.88520881]\n",
      " [ 0.22593937  0.71823511  0.470175    0.54324551]\n",
      " [-1.26650418 -0.18900924 -1.32372345 -1.40464674]\n",
      " [-1.01776359  0.9450462  -1.38159115 -1.14492778]\n",
      " [-1.51524477  1.17185729 -1.55519422 -1.27478726]\n",
      " [-1.26650418  0.71823511 -1.03438499 -1.27478726]\n",
      " [-0.14717152 -0.64263142  0.23870423  0.15366706]\n",
      " [-0.52028241  1.39866837 -1.26585576 -1.27478726]\n",
      " [ 0.10156908 -0.18900924  0.81738115  0.80296447]\n",
      " [ 0.22593937 -0.18900924  0.64377807  0.80296447]\n",
      " [-1.14213389  0.03780185 -1.26585576 -1.40464674]\n",
      " [-0.52028241  0.71823511 -1.15012038 -1.27478726]\n",
      " [-0.769023   -0.8694425   0.12296885  0.28352654]\n",
      " [-1.01776359 -0.18900924 -1.20798807 -1.27478726]\n",
      " [-0.89339329  1.62547946 -1.20798807 -1.27478726]\n",
      " [-0.89339329  1.39866837 -1.26585576 -1.01506829]\n",
      " [-0.52028241  1.85229055 -1.15012038 -1.01506829]\n",
      " [-0.769023    0.9450462  -1.26585576 -1.27478726]\n",
      " [ 0.72342056  0.26461294  0.470175    0.41338602]\n",
      " [ 0.72342056  0.03780185  1.04885192  0.80296447]\n",
      " [-0.14717152 -0.18900924  0.29657192  0.02380757]\n",
      " [ 2.34023441 -1.09625359  1.85899961  1.45226189]]\n",
      "******************************************************************************************\n",
      "[[ 0.72342056 -0.64263142  1.10671961  1.3224024 ]\n",
      " [-1.01776359  0.9450462  -1.20798807 -0.75534933]\n",
      " [-0.39591211 -1.32306468  0.18083654  0.15366706]\n",
      " [ 1.71838292 -0.18900924  1.22245499  0.54324551]\n",
      " [ 0.59905026 -1.32306468  0.70164577  0.41338602]\n",
      " [-1.26650418  0.03780185 -1.20798807 -1.27478726]\n",
      " [-0.27154181 -1.32306468  0.12296885 -0.10605191]\n",
      " [-1.14213389 -1.32306468  0.470175    0.67310499]\n",
      " [ 0.35030967 -1.09625359  1.10671961  0.28352654]\n",
      " [-0.02280122 -0.8694425   0.81738115  0.93282395]\n",
      " [ 0.10156908  0.26461294  0.64377807  0.80296447]\n",
      " [ 1.09653144 -0.18900924  0.75951346  0.67310499]\n",
      " [-1.14213389 -0.18900924 -1.32372345 -1.27478726]\n",
      " [-0.89339329  0.9450462  -1.32372345 -1.27478726]\n",
      " [ 0.47467996 -0.64263142  0.64377807  0.80296447]\n",
      " [-0.769023    0.71823511 -1.32372345 -1.27478726]\n",
      " [ 0.59905026  0.49142402  0.58591038  0.54324551]\n",
      " [-1.01776359  0.49142402 -1.32372345 -1.27478726]\n",
      " [-0.02280122 -0.8694425   0.12296885  0.02380757]\n",
      " [ 1.09653144 -1.32306468  1.22245499  0.80296447]\n",
      " [ 0.72342056 -0.8694425   0.93311653  0.93282395]\n",
      " [-0.89339329  1.62547946 -1.26585576 -1.14492778]\n",
      " [-1.01776359  0.26461294 -1.43945884 -1.27478726]\n",
      " [ 0.72342056 -0.64263142  1.10671961  1.19254292]\n",
      " [ 2.34023441 -0.64263142  1.74326422  1.06268344]\n",
      " [-0.27154181 -0.8694425   0.29657192  0.15366706]\n",
      " [ 1.34527204  0.03780185  0.70164577  0.41338602]\n",
      " [ 2.34023441  1.62547946  1.74326422  1.3224024 ]\n",
      " [-1.63961507 -1.77668685 -1.38159115 -1.14492778]\n",
      " [ 2.21586411 -0.18900924  1.68539653  1.19254292]]\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理 归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "train=scaler.transform(train)\n",
    "# 4.对测试数据进行归一化处理\n",
    "test=scaler.transform(test)\n",
    "print(train)\n",
    "print('*'*90)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNet,self).__init__()\n",
    "        self.fc = nn.Sequential( #添加神经元以及激活函数\n",
    "            nn.Linear(4,18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,3),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.mse=nn.CrossEntropyLoss()\n",
    "        self.optim=torch.optim.Adam(params=self.parameters(),lr=0.02)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        outputs=self.fc(inputs)\n",
    "        return outputs\n",
    "    \n",
    "    def train(self,x,label):\n",
    "        out=self.forward(x) #正向传播\n",
    "        loss=self.mse(out,label) #根据正向传播计算损失\n",
    "        self.optim.zero_grad()#梯度清零\n",
    "        loss.backward()#计算梯度\n",
    "        self.optim.step()#应用梯度更新参数\n",
    "        \n",
    "    def test(self,test_):\n",
    "        return self.fc(test_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Step:  0 | batch y:  [0 0 2 2 2]\n",
      "Epoch:  0 | Step:  1 | batch y:  [2 0 0 2 2]\n",
      "Epoch:  0 | Step:  2 | batch y:  [2 0 0 1 2]\n",
      "Epoch:  0 | Step:  3 | batch y:  [2 0 2 0 0]\n",
      "Epoch:  0 | Step:  4 | batch y:  [2 0 1 2 1]\n",
      "Epoch:  0 | Step:  5 | batch y:  [1 2 2 2 1]\n",
      "Epoch:  0 | Step:  6 | batch y:  [1 0 1 2 1]\n",
      "Epoch:  0 | Step:  7 | batch y:  [2 0 0 1 1]\n",
      "Epoch:  0 | Step:  8 | batch y:  [1 1 0 1 2]\n",
      "Epoch:  0 | Step:  9 | batch y:  [0 2 2 2 2]\n",
      "Epoch:  0 | Step:  10 | batch y:  [1 0 0 1 1]\n",
      "Epoch:  0 | Step:  11 | batch y:  [1 2 1 1 1]\n",
      "Epoch:  0 | Step:  12 | batch y:  [1 0 2 2 1]\n",
      "Epoch:  0 | Step:  13 | batch y:  [2 1 2 0 1]\n",
      "Epoch:  0 | Step:  14 | batch y:  [1 1 1 0 0]\n",
      "Epoch:  0 | Step:  15 | batch y:  [2 2 2 0 1]\n",
      "Epoch:  0 | Step:  16 | batch y:  [1 2 2 1 0]\n",
      "Epoch:  0 | Step:  17 | batch y:  [2 2 1 0 0]\n",
      "Epoch:  0 | Step:  18 | batch y:  [1 0 1 1 0]\n",
      "Epoch:  0 | Step:  19 | batch y:  [0 2 2 2 1]\n",
      "Epoch:  0 | Step:  20 | batch y:  [1 1 1 1 2]\n",
      "Epoch:  0 | Step:  21 | batch y:  [1 1 0 0 0]\n",
      "Epoch:  0 | Step:  22 | batch y:  [0 0 2 1 1]\n",
      "Epoch:  0 | Step:  23 | batch y:  [2 0 0 0 2]\n",
      "Epoch:  10 | Step:  0 | batch y:  [1 2 1 2 0]\n",
      "Epoch:  10 | Step:  1 | batch y:  [2 2 1 1 0]\n",
      "Epoch:  10 | Step:  2 | batch y:  [0 2 0 0 2]\n",
      "Epoch:  10 | Step:  3 | batch y:  [0 2 2 1 2]\n",
      "Epoch:  10 | Step:  4 | batch y:  [0 2 2 0 2]\n",
      "Epoch:  10 | Step:  5 | batch y:  [1 2 2 0 1]\n",
      "Epoch:  10 | Step:  6 | batch y:  [2 0 1 2 1]\n",
      "Epoch:  10 | Step:  7 | batch y:  [0 2 0 1 1]\n",
      "Epoch:  10 | Step:  8 | batch y:  [2 0 1 1 1]\n",
      "Epoch:  10 | Step:  9 | batch y:  [2 1 2 1 0]\n",
      "Epoch:  10 | Step:  10 | batch y:  [2 1 2 0 0]\n",
      "Epoch:  10 | Step:  11 | batch y:  [0 1 2 2 1]\n",
      "Epoch:  10 | Step:  12 | batch y:  [1 1 0 1 0]\n",
      "Epoch:  10 | Step:  13 | batch y:  [0 1 2 0 0]\n",
      "Epoch:  10 | Step:  14 | batch y:  [1 1 1 1 1]\n",
      "Epoch:  10 | Step:  15 | batch y:  [2 0 0 2 2]\n",
      "Epoch:  10 | Step:  16 | batch y:  [1 0 1 2 2]\n",
      "Epoch:  10 | Step:  17 | batch y:  [0 2 0 2 0]\n",
      "Epoch:  10 | Step:  18 | batch y:  [1 0 0 1 1]\n",
      "Epoch:  10 | Step:  19 | batch y:  [0 2 1 2 0]\n",
      "Epoch:  10 | Step:  20 | batch y:  [2 1 1 2 1]\n",
      "Epoch:  10 | Step:  21 | batch y:  [1 1 2 1 2]\n",
      "Epoch:  10 | Step:  22 | batch y:  [1 2 0 2 1]\n",
      "Epoch:  10 | Step:  23 | batch y:  [0 0 1 2 0]\n",
      "Epoch:  20 | Step:  0 | batch y:  [1 0 0 0 1]\n",
      "Epoch:  20 | Step:  1 | batch y:  [0 1 1 2 0]\n",
      "Epoch:  20 | Step:  2 | batch y:  [2 2 1 1 0]\n",
      "Epoch:  20 | Step:  3 | batch y:  [1 2 0 2 2]\n",
      "Epoch:  20 | Step:  4 | batch y:  [1 0 2 1 0]\n",
      "Epoch:  20 | Step:  5 | batch y:  [0 1 0 2 0]\n",
      "Epoch:  20 | Step:  6 | batch y:  [2 1 1 0 1]\n",
      "Epoch:  20 | Step:  7 | batch y:  [0 2 2 0 2]\n",
      "Epoch:  20 | Step:  8 | batch y:  [2 2 0 2 1]\n",
      "Epoch:  20 | Step:  9 | batch y:  [1 2 2 1 1]\n",
      "Epoch:  20 | Step:  10 | batch y:  [1 0 1 0 2]\n",
      "Epoch:  20 | Step:  11 | batch y:  [2 1 2 0 2]\n",
      "Epoch:  20 | Step:  12 | batch y:  [1 2 2 2 2]\n",
      "Epoch:  20 | Step:  13 | batch y:  [2 2 2 0 2]\n",
      "Epoch:  20 | Step:  14 | batch y:  [2 1 1 0 0]\n",
      "Epoch:  20 | Step:  15 | batch y:  [0 2 1 0 2]\n",
      "Epoch:  20 | Step:  16 | batch y:  [1 0 2 1 0]\n",
      "Epoch:  20 | Step:  17 | batch y:  [1 2 1 0 1]\n",
      "Epoch:  20 | Step:  18 | batch y:  [2 0 1 0 2]\n",
      "Epoch:  20 | Step:  19 | batch y:  [1 0 1 2 1]\n",
      "Epoch:  20 | Step:  20 | batch y:  [1 1 1 2 0]\n",
      "Epoch:  20 | Step:  21 | batch y:  [0 1 1 2 1]\n",
      "Epoch:  20 | Step:  22 | batch y:  [1 0 0 0 2]\n",
      "Epoch:  20 | Step:  23 | batch y:  [0 2 1 1 1]\n",
      "Epoch:  30 | Step:  0 | batch y:  [0 2 1 2 1]\n",
      "Epoch:  30 | Step:  1 | batch y:  [0 1 1 0 1]\n",
      "Epoch:  30 | Step:  2 | batch y:  [0 2 2 2 1]\n",
      "Epoch:  30 | Step:  3 | batch y:  [1 1 0 0 0]\n",
      "Epoch:  30 | Step:  4 | batch y:  [0 2 2 2 1]\n",
      "Epoch:  30 | Step:  5 | batch y:  [1 1 1 1 1]\n",
      "Epoch:  30 | Step:  6 | batch y:  [1 1 0 1 2]\n",
      "Epoch:  30 | Step:  7 | batch y:  [0 2 2 0 2]\n",
      "Epoch:  30 | Step:  8 | batch y:  [2 2 2 2 1]\n",
      "Epoch:  30 | Step:  9 | batch y:  [2 0 1 1 1]\n",
      "Epoch:  30 | Step:  10 | batch y:  [1 1 1 2 0]\n",
      "Epoch:  30 | Step:  11 | batch y:  [2 0 0 0 0]\n",
      "Epoch:  30 | Step:  12 | batch y:  [2 2 1 2 1]\n",
      "Epoch:  30 | Step:  13 | batch y:  [0 1 2 0 2]\n",
      "Epoch:  30 | Step:  14 | batch y:  [2 0 2 2 1]\n",
      "Epoch:  30 | Step:  15 | batch y:  [1 2 0 2 1]\n",
      "Epoch:  30 | Step:  16 | batch y:  [0 2 2 2 2]\n",
      "Epoch:  30 | Step:  17 | batch y:  [1 0 0 0 2]\n",
      "Epoch:  30 | Step:  18 | batch y:  [2 1 1 1 1]\n",
      "Epoch:  30 | Step:  19 | batch y:  [2 1 0 1 0]\n",
      "Epoch:  30 | Step:  20 | batch y:  [1 2 1 0 0]\n",
      "Epoch:  30 | Step:  21 | batch y:  [0 0 1 0 2]\n",
      "Epoch:  30 | Step:  22 | batch y:  [2 1 0 2 1]\n",
      "Epoch:  30 | Step:  23 | batch y:  [0 1 2 0 0]\n",
      "Epoch:  40 | Step:  0 | batch y:  [1 2 0 2 2]\n",
      "Epoch:  40 | Step:  1 | batch y:  [1 2 2 1 0]\n",
      "Epoch:  40 | Step:  2 | batch y:  [2 2 0 1 0]\n",
      "Epoch:  40 | Step:  3 | batch y:  [1 1 0 2 0]\n",
      "Epoch:  40 | Step:  4 | batch y:  [1 1 0 0 2]\n",
      "Epoch:  40 | Step:  5 | batch y:  [0 1 2 1 1]\n",
      "Epoch:  40 | Step:  6 | batch y:  [0 1 1 1 2]\n",
      "Epoch:  40 | Step:  7 | batch y:  [1 2 1 0 1]\n",
      "Epoch:  40 | Step:  8 | batch y:  [2 2 2 2 2]\n",
      "Epoch:  40 | Step:  9 | batch y:  [2 2 2 0 2]\n",
      "Epoch:  40 | Step:  10 | batch y:  [1 1 2 2 0]\n",
      "Epoch:  40 | Step:  11 | batch y:  [0 2 1 1 2]\n",
      "Epoch:  40 | Step:  12 | batch y:  [0 0 0 1 1]\n",
      "Epoch:  40 | Step:  13 | batch y:  [2 1 2 0 2]\n",
      "Epoch:  40 | Step:  14 | batch y:  [2 0 2 2 0]\n",
      "Epoch:  40 | Step:  15 | batch y:  [1 2 2 1 1]\n",
      "Epoch:  40 | Step:  16 | batch y:  [0 1 1 1 1]\n",
      "Epoch:  40 | Step:  17 | batch y:  [2 0 1 1 1]\n",
      "Epoch:  40 | Step:  18 | batch y:  [0 0 2 1 1]\n",
      "Epoch:  40 | Step:  19 | batch y:  [0 1 0 2 0]\n",
      "Epoch:  40 | Step:  20 | batch y:  [1 1 0 2 0]\n",
      "Epoch:  40 | Step:  21 | batch y:  [0 1 0 0 2]\n",
      "Epoch:  40 | Step:  22 | batch y:  [1 2 0 0 1]\n",
      "Epoch:  40 | Step:  23 | batch y:  [0 2 1 0 2]\n",
      "Epoch:  50 | Step:  0 | batch y:  [1 2 1 0 1]\n",
      "Epoch:  50 | Step:  1 | batch y:  [1 1 0 1 1]\n",
      "Epoch:  50 | Step:  2 | batch y:  [2 2 0 1 1]\n",
      "Epoch:  50 | Step:  3 | batch y:  [1 2 0 2 0]\n",
      "Epoch:  50 | Step:  4 | batch y:  [0 0 1 0 2]\n",
      "Epoch:  50 | Step:  5 | batch y:  [2 1 0 2 2]\n",
      "Epoch:  50 | Step:  6 | batch y:  [1 1 2 2 0]\n",
      "Epoch:  50 | Step:  7 | batch y:  [0 2 0 2 1]\n",
      "Epoch:  50 | Step:  8 | batch y:  [2 0 0 1 1]\n",
      "Epoch:  50 | Step:  9 | batch y:  [0 2 0 0 0]\n",
      "Epoch:  50 | Step:  10 | batch y:  [1 1 1 1 1]\n",
      "Epoch:  50 | Step:  11 | batch y:  [2 2 0 2 0]\n",
      "Epoch:  50 | Step:  12 | batch y:  [1 2 2 2 0]\n",
      "Epoch:  50 | Step:  13 | batch y:  [2 0 2 1 2]\n",
      "Epoch:  50 | Step:  14 | batch y:  [0 1 2 1 1]\n",
      "Epoch:  50 | Step:  15 | batch y:  [0 1 1 0 2]\n",
      "Epoch:  50 | Step:  16 | batch y:  [1 1 2 2 1]\n",
      "Epoch:  50 | Step:  17 | batch y:  [2 2 2 2 1]\n",
      "Epoch:  50 | Step:  18 | batch y:  [1 0 1 1 2]\n",
      "Epoch:  50 | Step:  19 | batch y:  [0 0 2 1 2]\n",
      "Epoch:  50 | Step:  20 | batch y:  [2 0 2 2 0]\n",
      "Epoch:  50 | Step:  21 | batch y:  [2 0 1 0 1]\n",
      "Epoch:  50 | Step:  22 | batch y:  [1 0 2 0 0]\n",
      "Epoch:  50 | Step:  23 | batch y:  [2 1 0 1 1]\n",
      "Epoch:  60 | Step:  0 | batch y:  [1 0 0 1 2]\n",
      "Epoch:  60 | Step:  1 | batch y:  [1 0 0 2 1]\n",
      "Epoch:  60 | Step:  2 | batch y:  [2 1 2 0 1]\n",
      "Epoch:  60 | Step:  3 | batch y:  [1 0 1 1 2]\n",
      "Epoch:  60 | Step:  4 | batch y:  [2 1 2 0 1]\n",
      "Epoch:  60 | Step:  5 | batch y:  [2 1 0 1 0]\n",
      "Epoch:  60 | Step:  6 | batch y:  [1 2 1 0 2]\n",
      "Epoch:  60 | Step:  7 | batch y:  [2 0 2 0 2]\n",
      "Epoch:  60 | Step:  8 | batch y:  [0 1 1 2 2]\n",
      "Epoch:  60 | Step:  9 | batch y:  [0 0 0 1 0]\n",
      "Epoch:  60 | Step:  10 | batch y:  [2 2 1 2 0]\n",
      "Epoch:  60 | Step:  11 | batch y:  [1 2 2 1 1]\n",
      "Epoch:  60 | Step:  12 | batch y:  [2 1 0 2 1]\n",
      "Epoch:  60 | Step:  13 | batch y:  [1 2 2 2 0]\n",
      "Epoch:  60 | Step:  14 | batch y:  [1 0 1 0 1]\n",
      "Epoch:  60 | Step:  15 | batch y:  [2 0 2 1 0]\n",
      "Epoch:  60 | Step:  16 | batch y:  [1 0 2 1 0]\n",
      "Epoch:  60 | Step:  17 | batch y:  [2 1 0 2 1]\n",
      "Epoch:  60 | Step:  18 | batch y:  [1 1 1 0 0]\n",
      "Epoch:  60 | Step:  19 | batch y:  [0 0 0 2 0]\n",
      "Epoch:  60 | Step:  20 | batch y:  [1 1 1 1 0]\n",
      "Epoch:  60 | Step:  21 | batch y:  [2 2 2 0 2]\n",
      "Epoch:  60 | Step:  22 | batch y:  [2 2 2 1 2]\n",
      "Epoch:  60 | Step:  23 | batch y:  [1 2 1 2 0]\n",
      "Epoch:  70 | Step:  0 | batch y:  [2 2 0 2 0]\n",
      "Epoch:  70 | Step:  1 | batch y:  [2 0 1 2 2]\n",
      "Epoch:  70 | Step:  2 | batch y:  [1 0 1 1 1]\n",
      "Epoch:  70 | Step:  3 | batch y:  [0 1 2 2 2]\n",
      "Epoch:  70 | Step:  4 | batch y:  [2 1 0 0 1]\n",
      "Epoch:  70 | Step:  5 | batch y:  [1 1 0 0 0]\n",
      "Epoch:  70 | Step:  6 | batch y:  [1 2 1 0 2]\n",
      "Epoch:  70 | Step:  7 | batch y:  [0 1 2 1 0]\n",
      "Epoch:  70 | Step:  8 | batch y:  [1 2 1 2 0]\n",
      "Epoch:  70 | Step:  9 | batch y:  [2 2 2 1 0]\n",
      "Epoch:  70 | Step:  10 | batch y:  [2 1 2 0 0]\n",
      "Epoch:  70 | Step:  11 | batch y:  [0 0 1 0 0]\n",
      "Epoch:  70 | Step:  12 | batch y:  [2 2 1 2 0]\n",
      "Epoch:  70 | Step:  13 | batch y:  [1 0 1 1 1]\n",
      "Epoch:  70 | Step:  14 | batch y:  [1 1 0 2 1]\n",
      "Epoch:  70 | Step:  15 | batch y:  [1 1 1 1 0]\n",
      "Epoch:  70 | Step:  16 | batch y:  [1 1 2 2 2]\n",
      "Epoch:  70 | Step:  17 | batch y:  [2 2 0 0 2]\n",
      "Epoch:  70 | Step:  18 | batch y:  [0 0 1 2 2]\n",
      "Epoch:  70 | Step:  19 | batch y:  [2 0 1 0 0]\n",
      "Epoch:  70 | Step:  20 | batch y:  [2 0 2 1 2]\n",
      "Epoch:  70 | Step:  21 | batch y:  [1 1 2 2 2]\n",
      "Epoch:  70 | Step:  22 | batch y:  [1 0 2 0 1]\n",
      "Epoch:  70 | Step:  23 | batch y:  [1 0 1 1 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  80 | Step:  0 | batch y:  [2 2 1 2 2]\n",
      "Epoch:  80 | Step:  1 | batch y:  [2 0 1 1 1]\n",
      "Epoch:  80 | Step:  2 | batch y:  [1 0 2 1 2]\n",
      "Epoch:  80 | Step:  3 | batch y:  [2 2 0 2 2]\n",
      "Epoch:  80 | Step:  4 | batch y:  [2 2 1 0 2]\n",
      "Epoch:  80 | Step:  5 | batch y:  [1 1 0 1 2]\n",
      "Epoch:  80 | Step:  6 | batch y:  [1 1 0 0 1]\n",
      "Epoch:  80 | Step:  7 | batch y:  [0 0 2 2 0]\n",
      "Epoch:  80 | Step:  8 | batch y:  [1 0 1 1 2]\n",
      "Epoch:  80 | Step:  9 | batch y:  [1 1 2 2 0]\n",
      "Epoch:  80 | Step:  10 | batch y:  [2 0 2 2 0]\n",
      "Epoch:  80 | Step:  11 | batch y:  [2 1 1 0 1]\n",
      "Epoch:  80 | Step:  12 | batch y:  [2 1 0 1 1]\n",
      "Epoch:  80 | Step:  13 | batch y:  [2 1 0 2 2]\n",
      "Epoch:  80 | Step:  14 | batch y:  [1 1 2 1 0]\n",
      "Epoch:  80 | Step:  15 | batch y:  [2 0 1 2 1]\n",
      "Epoch:  80 | Step:  16 | batch y:  [2 1 0 0 2]\n",
      "Epoch:  80 | Step:  17 | batch y:  [0 0 0 2 1]\n",
      "Epoch:  80 | Step:  18 | batch y:  [0 0 1 1 2]\n",
      "Epoch:  80 | Step:  19 | batch y:  [1 2 2 1 1]\n",
      "Epoch:  80 | Step:  20 | batch y:  [0 0 0 0 1]\n",
      "Epoch:  80 | Step:  21 | batch y:  [0 2 1 2 2]\n",
      "Epoch:  80 | Step:  22 | batch y:  [0 0 1 1 1]\n",
      "Epoch:  80 | Step:  23 | batch y:  [2 0 1 0 0]\n",
      "Epoch:  90 | Step:  0 | batch y:  [1 2 2 0 0]\n",
      "Epoch:  90 | Step:  1 | batch y:  [0 0 2 0 2]\n",
      "Epoch:  90 | Step:  2 | batch y:  [2 0 0 1 2]\n",
      "Epoch:  90 | Step:  3 | batch y:  [1 1 1 1 1]\n",
      "Epoch:  90 | Step:  4 | batch y:  [1 0 0 2 1]\n",
      "Epoch:  90 | Step:  5 | batch y:  [2 1 2 2 2]\n",
      "Epoch:  90 | Step:  6 | batch y:  [2 2 0 0 2]\n",
      "Epoch:  90 | Step:  7 | batch y:  [0 1 2 1 1]\n",
      "Epoch:  90 | Step:  8 | batch y:  [1 1 2 0 1]\n",
      "Epoch:  90 | Step:  9 | batch y:  [1 2 1 1 0]\n",
      "Epoch:  90 | Step:  10 | batch y:  [2 2 0 0 2]\n",
      "Epoch:  90 | Step:  11 | batch y:  [1 0 1 2 0]\n",
      "Epoch:  90 | Step:  12 | batch y:  [2 1 0 1 0]\n",
      "Epoch:  90 | Step:  13 | batch y:  [2 2 2 1 2]\n",
      "Epoch:  90 | Step:  14 | batch y:  [2 1 0 2 0]\n",
      "Epoch:  90 | Step:  15 | batch y:  [1 0 2 2 1]\n",
      "Epoch:  90 | Step:  16 | batch y:  [1 1 0 0 1]\n",
      "Epoch:  90 | Step:  17 | batch y:  [0 2 1 0 2]\n",
      "Epoch:  90 | Step:  18 | batch y:  [2 1 0 0 2]\n",
      "Epoch:  90 | Step:  19 | batch y:  [2 1 2 2 1]\n",
      "Epoch:  90 | Step:  20 | batch y:  [0 1 2 0 1]\n",
      "Epoch:  90 | Step:  21 | batch y:  [0 0 0 2 1]\n",
      "Epoch:  90 | Step:  22 | batch y:  [2 0 1 1 1]\n",
      "Epoch:  90 | Step:  23 | batch y:  [1 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "data,labels,train,test,train_label,test_label=getdata()\n",
    "iris_net=IrisNet()\n",
    "train_dataset = Data.TensorDataset(torch.from_numpy(train).float(),torch.from_numpy(train_label).long())\n",
    "BATCH_SIZE=5\n",
    "train_loader = Data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "for epoch in range(100):\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        y=torch.reshape(y,[BATCH_SIZE])\n",
    "        iris_net.train(x,y)\n",
    "        if epoch%10==0:\n",
    "            print('Epoch: ', epoch, '| Step: ', step, '| batch y: ', y.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "莺尾花预测准确率 1.0\n"
     ]
    }
   ],
   "source": [
    "# 查看训练效果 测试集\n",
    "out=iris_net.test(torch.from_numpy(test).float())\n",
    "prediction = torch.max(out, 1)[1]# 1返回index  0返回原值\n",
    "y_pred = prediction.data.numpy()\n",
    "y_true=test_label.reshape(1,-1)[0]\n",
    "accuracy = float((y_pred == y_true).astype(int).sum()) / (len(y_true))\n",
    "print(\"莺尾花预测准确率\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key savefig.frameon in file /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/sk49/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 衡量模型性能\n",
    "\n",
    "#true↓ predict→\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(y_pred, y_true)\n",
    "#print(cm)\n",
    "plt.matshow(cm,cmap=plt.cm.Greens)\n",
    "plt.colorbar()\n",
    "for x in range(len(cm)):\n",
    "    for y in range(len(cm)):\n",
    "        plt.annotate(cm[x,y],xy=(x,y),horizontalalignment='center',verticalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类报告为：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        14\n",
      "         1.0       1.00      1.00      1.00         7\n",
      "         2.0       1.00      1.00      1.00         9\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 分类报告\n",
    "r = sm.classification_report(y_true, y_pred)\n",
    "print('分类报告为：', r, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
