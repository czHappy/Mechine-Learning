{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from  sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata():\n",
    "    train_data=load_iris()\n",
    "    data=train_data['data']\n",
    "    labels=train_data['target'].reshape(-1,1)\n",
    "    total_data=np.hstack((data,labels))\n",
    "    np.random.shuffle(total_data)\n",
    "    train=total_data[0:100,:-1]\n",
    "    test=total_data[100:,:-1]\n",
    "    train_label=total_data[0:100,-1].reshape(-1,1)\n",
    "    test_label=total_data[100:,-1].reshape(-1,1)\n",
    "    return data,labels,train,test,train_label,test_label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "******************************************************************************************\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "******************************************************************************************\n",
      "[[5.5 4.2 1.4 0.2]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.  3.  1.6 0.2]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "******************************************************************************************\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "data,labels,train,test,train_label,test_label = getdata()\n",
    "print(data)\n",
    "print('*'*90)\n",
    "print(labels)\n",
    "print('*'*90)\n",
    "print(train)\n",
    "print('*'*90)\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNet,self).__init__()\n",
    "        self.fc = nn.Sequential( #添加神经元以及激活函数\n",
    "            nn.Linear(4,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30,3)\n",
    "        )\n",
    "        self.mse=nn.CrossEntropyLoss()\n",
    "        self.optim=torch.optim.Adam(params=self.parameters(),lr=0.02)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        outputs=self.fc(inputs)\n",
    "        return outputs\n",
    "    \n",
    "    def train(self,x,label):\n",
    "        out=self.forward(x) #正向传播\n",
    "        loss=self.mse(out,label) #根据正向传播计算损失\n",
    "        self.optim.zero_grad()#梯度清零\n",
    "        loss.backward()#计算梯度\n",
    "        self.optim.step()#应用梯度更新参数\n",
    "        \n",
    "    def test(self,test_):\n",
    "        return self.fc(test_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Step:  0 | batch y:  [0 2 1 2 0]\n",
      "Epoch:  0 | Step:  1 | batch y:  [0 0 0 0 0]\n",
      "Epoch:  0 | Step:  2 | batch y:  [1 2 1 1 0]\n",
      "Epoch:  0 | Step:  3 | batch y:  [2 1 1 2 1]\n",
      "Epoch:  0 | Step:  4 | batch y:  [2 2 2 0 2]\n",
      "Epoch:  0 | Step:  5 | batch y:  [1 2 1 1 1]\n",
      "Epoch:  0 | Step:  6 | batch y:  [2 2 0 0 0]\n",
      "Epoch:  0 | Step:  7 | batch y:  [1 1 1 0 1]\n",
      "Epoch:  0 | Step:  8 | batch y:  [0 0 0 1 1]\n",
      "Epoch:  0 | Step:  9 | batch y:  [1 1 0 0 2]\n",
      "Epoch:  0 | Step:  10 | batch y:  [2 0 1 2 1]\n",
      "Epoch:  0 | Step:  11 | batch y:  [1 2 0 1 0]\n",
      "Epoch:  0 | Step:  12 | batch y:  [0 1 1 0 2]\n",
      "Epoch:  0 | Step:  13 | batch y:  [0 0 0 1 2]\n",
      "Epoch:  0 | Step:  14 | batch y:  [1 1 2 0 1]\n",
      "Epoch:  0 | Step:  15 | batch y:  [1 2 1 2 0]\n",
      "Epoch:  0 | Step:  16 | batch y:  [2 0 2 1 2]\n",
      "Epoch:  0 | Step:  17 | batch y:  [2 0 1 2 0]\n",
      "Epoch:  0 | Step:  18 | batch y:  [0 1 0 1 1]\n",
      "Epoch:  0 | Step:  19 | batch y:  [1 0 2 1 1]\n",
      "Epoch:  10 | Step:  0 | batch y:  [1 2 1 1 1]\n",
      "Epoch:  10 | Step:  1 | batch y:  [1 0 0 1 0]\n",
      "Epoch:  10 | Step:  2 | batch y:  [2 1 2 0 0]\n",
      "Epoch:  10 | Step:  3 | batch y:  [1 1 0 1 1]\n",
      "Epoch:  10 | Step:  4 | batch y:  [0 0 1 0 0]\n",
      "Epoch:  10 | Step:  5 | batch y:  [1 2 1 0 1]\n",
      "Epoch:  10 | Step:  6 | batch y:  [1 2 2 0 2]\n",
      "Epoch:  10 | Step:  7 | batch y:  [1 0 1 1 1]\n",
      "Epoch:  10 | Step:  8 | batch y:  [1 1 0 0 0]\n",
      "Epoch:  10 | Step:  9 | batch y:  [0 2 0 2 1]\n",
      "Epoch:  10 | Step:  10 | batch y:  [2 2 1 0 0]\n",
      "Epoch:  10 | Step:  11 | batch y:  [1 0 1 0 1]\n",
      "Epoch:  10 | Step:  12 | batch y:  [2 0 1 1 0]\n",
      "Epoch:  10 | Step:  13 | batch y:  [2 1 2 0 1]\n",
      "Epoch:  10 | Step:  14 | batch y:  [1 1 2 2 2]\n",
      "Epoch:  10 | Step:  15 | batch y:  [0 2 0 1 2]\n",
      "Epoch:  10 | Step:  16 | batch y:  [0 1 0 0 1]\n",
      "Epoch:  10 | Step:  17 | batch y:  [2 2 2 0 0]\n",
      "Epoch:  10 | Step:  18 | batch y:  [1 1 1 2 2]\n",
      "Epoch:  10 | Step:  19 | batch y:  [2 0 2 0 2]\n",
      "Epoch:  20 | Step:  0 | batch y:  [2 0 1 2 1]\n",
      "Epoch:  20 | Step:  1 | batch y:  [0 2 1 0 1]\n",
      "Epoch:  20 | Step:  2 | batch y:  [1 2 0 0 0]\n",
      "Epoch:  20 | Step:  3 | batch y:  [1 1 2 0 1]\n",
      "Epoch:  20 | Step:  4 | batch y:  [0 1 1 1 0]\n",
      "Epoch:  20 | Step:  5 | batch y:  [1 2 0 1 1]\n",
      "Epoch:  20 | Step:  6 | batch y:  [0 1 1 0 2]\n",
      "Epoch:  20 | Step:  7 | batch y:  [1 1 1 2 2]\n",
      "Epoch:  20 | Step:  8 | batch y:  [0 2 2 2 1]\n",
      "Epoch:  20 | Step:  9 | batch y:  [2 1 2 0 1]\n",
      "Epoch:  20 | Step:  10 | batch y:  [0 2 1 2 1]\n",
      "Epoch:  20 | Step:  11 | batch y:  [0 0 0 0 1]\n",
      "Epoch:  20 | Step:  12 | batch y:  [0 1 1 2 1]\n",
      "Epoch:  20 | Step:  13 | batch y:  [1 2 0 2 0]\n",
      "Epoch:  20 | Step:  14 | batch y:  [1 1 0 2 1]\n",
      "Epoch:  20 | Step:  15 | batch y:  [2 1 0 2 0]\n",
      "Epoch:  20 | Step:  16 | batch y:  [0 1 0 0 2]\n",
      "Epoch:  20 | Step:  17 | batch y:  [0 0 0 1 2]\n",
      "Epoch:  20 | Step:  18 | batch y:  [0 1 0 1 1]\n",
      "Epoch:  20 | Step:  19 | batch y:  [2 0 2 2 1]\n",
      "Epoch:  30 | Step:  0 | batch y:  [0 1 2 0 1]\n",
      "Epoch:  30 | Step:  1 | batch y:  [0 0 0 0 1]\n",
      "Epoch:  30 | Step:  2 | batch y:  [2 0 0 1 0]\n",
      "Epoch:  30 | Step:  3 | batch y:  [0 0 1 1 1]\n",
      "Epoch:  30 | Step:  4 | batch y:  [2 2 1 0 0]\n",
      "Epoch:  30 | Step:  5 | batch y:  [1 1 0 2 0]\n",
      "Epoch:  30 | Step:  6 | batch y:  [0 0 1 1 0]\n",
      "Epoch:  30 | Step:  7 | batch y:  [1 1 2 1 2]\n",
      "Epoch:  30 | Step:  8 | batch y:  [1 1 1 2 2]\n",
      "Epoch:  30 | Step:  9 | batch y:  [0 1 2 0 0]\n",
      "Epoch:  30 | Step:  10 | batch y:  [2 1 0 0 0]\n",
      "Epoch:  30 | Step:  11 | batch y:  [2 2 0 1 1]\n",
      "Epoch:  30 | Step:  12 | batch y:  [2 0 0 1 0]\n",
      "Epoch:  30 | Step:  13 | batch y:  [0 0 2 0 1]\n",
      "Epoch:  30 | Step:  14 | batch y:  [2 0 1 2 1]\n",
      "Epoch:  30 | Step:  15 | batch y:  [1 1 2 2 2]\n",
      "Epoch:  30 | Step:  16 | batch y:  [2 1 2 2 1]\n",
      "Epoch:  30 | Step:  17 | batch y:  [1 1 0 1 2]\n",
      "Epoch:  30 | Step:  18 | batch y:  [1 1 1 2 2]\n",
      "Epoch:  30 | Step:  19 | batch y:  [1 2 0 1 1]\n",
      "Epoch:  40 | Step:  0 | batch y:  [2 1 2 2 1]\n",
      "Epoch:  40 | Step:  1 | batch y:  [0 1 0 0 2]\n",
      "Epoch:  40 | Step:  2 | batch y:  [1 0 0 0 1]\n",
      "Epoch:  40 | Step:  3 | batch y:  [0 0 0 1 1]\n",
      "Epoch:  40 | Step:  4 | batch y:  [1 1 1 0 1]\n",
      "Epoch:  40 | Step:  5 | batch y:  [0 0 1 1 2]\n",
      "Epoch:  40 | Step:  6 | batch y:  [1 0 1 1 2]\n",
      "Epoch:  40 | Step:  7 | batch y:  [0 2 0 1 1]\n",
      "Epoch:  40 | Step:  8 | batch y:  [0 0 1 2 2]\n",
      "Epoch:  40 | Step:  9 | batch y:  [0 2 0 2 2]\n",
      "Epoch:  40 | Step:  10 | batch y:  [1 2 1 1 2]\n",
      "Epoch:  40 | Step:  11 | batch y:  [0 0 1 1 2]\n",
      "Epoch:  40 | Step:  12 | batch y:  [1 1 0 2 1]\n",
      "Epoch:  40 | Step:  13 | batch y:  [0 1 2 2 0]\n",
      "Epoch:  40 | Step:  14 | batch y:  [0 0 1 1 1]\n",
      "Epoch:  40 | Step:  15 | batch y:  [2 2 1 1 1]\n",
      "Epoch:  40 | Step:  16 | batch y:  [0 0 1 1 0]\n",
      "Epoch:  40 | Step:  17 | batch y:  [0 0 2 2 2]\n",
      "Epoch:  40 | Step:  18 | batch y:  [2 2 1 0 2]\n",
      "Epoch:  40 | Step:  19 | batch y:  [2 0 1 1 0]\n",
      "Epoch:  50 | Step:  0 | batch y:  [0 1 2 2 0]\n",
      "Epoch:  50 | Step:  1 | batch y:  [0 0 1 0 2]\n",
      "Epoch:  50 | Step:  2 | batch y:  [1 0 1 0 1]\n",
      "Epoch:  50 | Step:  3 | batch y:  [2 2 2 1 0]\n",
      "Epoch:  50 | Step:  4 | batch y:  [2 1 0 0 2]\n",
      "Epoch:  50 | Step:  5 | batch y:  [0 2 1 1 1]\n",
      "Epoch:  50 | Step:  6 | batch y:  [0 1 2 1 0]\n",
      "Epoch:  50 | Step:  7 | batch y:  [1 1 0 2 0]\n",
      "Epoch:  50 | Step:  8 | batch y:  [1 0 2 0 2]\n",
      "Epoch:  50 | Step:  9 | batch y:  [1 1 1 1 1]\n",
      "Epoch:  50 | Step:  10 | batch y:  [0 1 2 2 1]\n",
      "Epoch:  50 | Step:  11 | batch y:  [1 2 2 0 1]\n",
      "Epoch:  50 | Step:  12 | batch y:  [1 2 0 2 0]\n",
      "Epoch:  50 | Step:  13 | batch y:  [2 0 1 0 1]\n",
      "Epoch:  50 | Step:  14 | batch y:  [1 2 0 1 0]\n",
      "Epoch:  50 | Step:  15 | batch y:  [1 0 0 2 0]\n",
      "Epoch:  50 | Step:  16 | batch y:  [1 1 1 0 2]\n",
      "Epoch:  50 | Step:  17 | batch y:  [1 0 2 2 1]\n",
      "Epoch:  50 | Step:  18 | batch y:  [1 1 2 0 1]\n",
      "Epoch:  50 | Step:  19 | batch y:  [1 2 0 0 0]\n",
      "Epoch:  60 | Step:  0 | batch y:  [0 2 2 1 2]\n",
      "Epoch:  60 | Step:  1 | batch y:  [0 0 1 1 1]\n",
      "Epoch:  60 | Step:  2 | batch y:  [1 1 2 0 1]\n",
      "Epoch:  60 | Step:  3 | batch y:  [0 0 1 2 1]\n",
      "Epoch:  60 | Step:  4 | batch y:  [1 0 0 0 2]\n",
      "Epoch:  60 | Step:  5 | batch y:  [1 1 0 1 0]\n",
      "Epoch:  60 | Step:  6 | batch y:  [2 2 0 1 0]\n",
      "Epoch:  60 | Step:  7 | batch y:  [2 0 0 2 1]\n",
      "Epoch:  60 | Step:  8 | batch y:  [2 1 0 2 1]\n",
      "Epoch:  60 | Step:  9 | batch y:  [1 2 0 0 1]\n",
      "Epoch:  60 | Step:  10 | batch y:  [2 1 1 0 1]\n",
      "Epoch:  60 | Step:  11 | batch y:  [1 1 2 1 0]\n",
      "Epoch:  60 | Step:  12 | batch y:  [0 1 0 2 1]\n",
      "Epoch:  60 | Step:  13 | batch y:  [0 1 0 1 0]\n",
      "Epoch:  60 | Step:  14 | batch y:  [2 2 2 1 1]\n",
      "Epoch:  60 | Step:  15 | batch y:  [1 1 2 0 0]\n",
      "Epoch:  60 | Step:  16 | batch y:  [2 1 2 1 0]\n",
      "Epoch:  60 | Step:  17 | batch y:  [1 2 2 2 0]\n",
      "Epoch:  60 | Step:  18 | batch y:  [1 1 2 2 0]\n",
      "Epoch:  60 | Step:  19 | batch y:  [0 1 0 0 0]\n",
      "Epoch:  70 | Step:  0 | batch y:  [2 0 0 0 0]\n",
      "Epoch:  70 | Step:  1 | batch y:  [1 0 2 1 2]\n",
      "Epoch:  70 | Step:  2 | batch y:  [0 2 2 0 2]\n",
      "Epoch:  70 | Step:  3 | batch y:  [1 0 1 1 1]\n",
      "Epoch:  70 | Step:  4 | batch y:  [0 2 2 1 1]\n",
      "Epoch:  70 | Step:  5 | batch y:  [1 2 2 1 0]\n",
      "Epoch:  70 | Step:  6 | batch y:  [1 0 1 1 1]\n",
      "Epoch:  70 | Step:  7 | batch y:  [2 2 1 1 2]\n",
      "Epoch:  70 | Step:  8 | batch y:  [0 0 0 1 1]\n",
      "Epoch:  70 | Step:  9 | batch y:  [2 0 2 2 1]\n",
      "Epoch:  70 | Step:  10 | batch y:  [1 1 2 1 2]\n",
      "Epoch:  70 | Step:  11 | batch y:  [1 2 2 2 2]\n",
      "Epoch:  70 | Step:  12 | batch y:  [0 1 1 1 1]\n",
      "Epoch:  70 | Step:  13 | batch y:  [2 0 1 0 2]\n",
      "Epoch:  70 | Step:  14 | batch y:  [1 0 1 0 1]\n",
      "Epoch:  70 | Step:  15 | batch y:  [1 0 1 0 0]\n",
      "Epoch:  70 | Step:  16 | batch y:  [1 0 0 0 1]\n",
      "Epoch:  70 | Step:  17 | batch y:  [1 2 1 0 1]\n",
      "Epoch:  70 | Step:  18 | batch y:  [0 0 0 0 2]\n",
      "Epoch:  70 | Step:  19 | batch y:  [0 1 0 2 0]\n",
      "Epoch:  80 | Step:  0 | batch y:  [2 0 1 1 0]\n",
      "Epoch:  80 | Step:  1 | batch y:  [0 2 1 1 1]\n",
      "Epoch:  80 | Step:  2 | batch y:  [1 2 2 2 1]\n",
      "Epoch:  80 | Step:  3 | batch y:  [0 1 0 2 0]\n",
      "Epoch:  80 | Step:  4 | batch y:  [0 1 2 2 2]\n",
      "Epoch:  80 | Step:  5 | batch y:  [1 0 0 1 1]\n",
      "Epoch:  80 | Step:  6 | batch y:  [0 1 1 1 0]\n",
      "Epoch:  80 | Step:  7 | batch y:  [2 2 2 2 0]\n",
      "Epoch:  80 | Step:  8 | batch y:  [2 0 1 0 0]\n",
      "Epoch:  80 | Step:  9 | batch y:  [0 1 1 2 1]\n",
      "Epoch:  80 | Step:  10 | batch y:  [2 2 2 1 1]\n",
      "Epoch:  80 | Step:  11 | batch y:  [0 1 2 1 0]\n",
      "Epoch:  80 | Step:  12 | batch y:  [0 0 0 2 0]\n",
      "Epoch:  80 | Step:  13 | batch y:  [2 0 2 2 0]\n",
      "Epoch:  80 | Step:  14 | batch y:  [2 1 1 1 1]\n",
      "Epoch:  80 | Step:  15 | batch y:  [0 1 2 1 1]\n",
      "Epoch:  80 | Step:  16 | batch y:  [0 1 1 0 0]\n",
      "Epoch:  80 | Step:  17 | batch y:  [1 0 0 0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  80 | Step:  18 | batch y:  [0 0 0 2 1]\n",
      "Epoch:  80 | Step:  19 | batch y:  [2 1 1 1 1]\n",
      "Epoch:  90 | Step:  0 | batch y:  [1 0 1 1 2]\n",
      "Epoch:  90 | Step:  1 | batch y:  [0 0 1 2 1]\n",
      "Epoch:  90 | Step:  2 | batch y:  [2 0 0 1 1]\n",
      "Epoch:  90 | Step:  3 | batch y:  [0 1 2 2 1]\n",
      "Epoch:  90 | Step:  4 | batch y:  [0 0 2 0 1]\n",
      "Epoch:  90 | Step:  5 | batch y:  [0 1 1 2 0]\n",
      "Epoch:  90 | Step:  6 | batch y:  [0 0 0 2 2]\n",
      "Epoch:  90 | Step:  7 | batch y:  [0 2 1 1 0]\n",
      "Epoch:  90 | Step:  8 | batch y:  [0 2 2 0 2]\n",
      "Epoch:  90 | Step:  9 | batch y:  [1 0 0 1 2]\n",
      "Epoch:  90 | Step:  10 | batch y:  [2 1 0 0 1]\n",
      "Epoch:  90 | Step:  11 | batch y:  [0 1 0 2 0]\n",
      "Epoch:  90 | Step:  12 | batch y:  [0 1 1 2 0]\n",
      "Epoch:  90 | Step:  13 | batch y:  [2 1 0 1 1]\n",
      "Epoch:  90 | Step:  14 | batch y:  [1 2 2 1 1]\n",
      "Epoch:  90 | Step:  15 | batch y:  [1 1 2 1 1]\n",
      "Epoch:  90 | Step:  16 | batch y:  [2 1 2 1 1]\n",
      "Epoch:  90 | Step:  17 | batch y:  [0 1 2 1 0]\n",
      "Epoch:  90 | Step:  18 | batch y:  [2 0 0 0 1]\n",
      "Epoch:  90 | Step:  19 | batch y:  [2 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "data,labels,train,test,train_label,test_label=getdata()\n",
    "iris_net=IrisNet()\n",
    "train_dataset = Data.TensorDataset(torch.from_numpy(train).float(),torch.from_numpy(train_label).long())\n",
    "BATCH_SIZE=5\n",
    "train_loader = Data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "for epoch in range(100):\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        y=torch.reshape(y,[BATCH_SIZE])\n",
    "        iris_net.train(x,y)\n",
    "        if epoch%10==0:\n",
    "            print('Epoch: ', epoch, '| Step: ', step, '| batch y: ', y.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "莺尾花预测准确率 0.97\n"
     ]
    }
   ],
   "source": [
    "# 查看训练效果 测试集\n",
    "out=iris_net.test(torch.from_numpy(train).float())\n",
    "prediction = torch.max(out, 1)[1]# 1返回index  0返回原值\n",
    "y_pred = prediction.data.numpy()\n",
    "y_true=train_label.reshape(1,-1)[0]\n",
    "accuracy = float((y_pred == y_true).astype(int).sum()) / (len(y_true))\n",
    "print(\"莺尾花预测准确率\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 衡量模型性能\n",
    "\n",
    "#true↓ predict→\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(y_pred, y_true)\n",
    "#print(cm)\n",
    "plt.matshow(cm,cmap=plt.cm.Greens)\n",
    "plt.colorbar()\n",
    "for x in range(len(cm)):\n",
    "    for y in range(len(cm)):\n",
    "        plt.annotate(cm[x,y],xy=(x,y),horizontalalignment='center',verticalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类报告为：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        34\n",
      "         1.0       1.00      0.92      0.96        39\n",
      "         2.0       0.90      1.00      0.95        27\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       100\n",
      "   macro avg       0.97      0.97      0.97       100\n",
      "weighted avg       0.97      0.97      0.97       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 分类报告\n",
    "r = sm.classification_report(y_true, y_pred)\n",
    "print('分类报告为：', r, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
